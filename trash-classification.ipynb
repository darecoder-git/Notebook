{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport numpy as np\nimport pandas as pd \nimport seaborn as sb\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"../input/garbage-classification/garbage classification/Garbage classification/\"))\n['metal', 'glass', 'paper', 'trash', 'cardboard', 'plastic']\nPreparing the data and Visualization\n\ntrash = pd.read_csv(\"/kaggle/input/garbage-classification/zero-indexed-files.txt\")\n\n\n    \n# print(filename ,end=\"\\n\")\n#Create new dataframe with two columns\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sb\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"../input/garbage-classification/garbage classification/Garbage classification/\"))\n['metal', 'glass', 'paper', 'trash', 'cardboard', 'plastic']\nPreparing the data and Visualization\n\ntrash = pd.read_csv(\"/kaggle/input/garbage-classification/zero-indexed-files.txt\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncategory = []\n# index = []\nfilename = []\nwith open(\"../input/garbage-classification/zero-indexed-files.txt\", \"r\") as file:\n    for line in file:     \n#      5>4?sd:dsds\n        # Category of the image (label) e.g. glass\n        cat = ''.join([i for i in line.split('.')[0] if not i.isdigit()])\n        category.append(cat)\n        \n        \n       #Image name e.g. glass/glass123.jpg\n        filename.append(cat+\"/\"+line.split(' ')[0])\n        \n        \n        #numerical value for category e.g. 0 for glass\n#         index.append((line.split(' ')[1]).strip()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\n    'filename':filename,\n    'category': category,\n#     'index': index\n})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.title('Count plot')\nsb.countplot(x = df['category'], data=df)\n#Index 0: glass, Index 1: paper, Index 2: cardboard, Index 3: plastic, Index 4: metal, Index 5: other\n<AxesSubplot:title={'center':'Count plot'}, xlabel='category', ylabel='count'>\n\nsample = random.choice(filename)\nfolder = ''.join([i for i in sample.split('.')[0] if not i.isdigit()])\n    \nimage = load_img(\"../input/garbage-classification/garbage classification/Garbage classification/\"+sample)\nplt.title(folder.split('/')[0])\nplt.imshow(image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nFAST_RUN = False\nIMAGE_WIDTH=300\nIMAGE_HEIGHT=300\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\n#padding='same' returns output whose value can be computed by applying the filter to all input elements. \n#Border elements are computed using zero padding. \n#The output may be same or smaller than the input depending on the stride option.\n\nmodel = Sequential([\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n\n    Flatten(),\n\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(6, activation='softmax') #6 because we have 6 categories\n])\n\n#Computes the crossentropy loss between the labels and predictions.\n#acc metric to be evaluated by the model during training and testing\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n#stop training when a monitored metric has stopped improving.\n#patience: number of epochs with no improvement after which training will be stopped.\nearlystop = EarlyStopping(patience=10)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', #quantity to be monitored (in this case total loss)\n                                            patience=2, #number of epochs with no improvement after which learning rate will be reduced\n                                            verbose=1, #0: quiet, 1: update messages\n                                            factor=0.5, #factor by which the learning rate will be reduced\n                                            min_lr=0.00001) #lower bound on the learning rate.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [earlystop, learning_rate_reduction]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['index'] = df['category'] #.replace({0: 'glass', 1: 'paper', 2: 'cardboard', 3: 'plastic', 4: 'metal', 5: 'trash'}) \n# df.drop('index', inplace=True, axis=1)\ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)#42 is the seed of randomness\n\n#Incase a column was part of an index\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\n\nsb.countplot(x = train_df['category'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.countplot(x = validate_df['category'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#.shape[0]: gives number of rows\n#batch_size: number of training examples\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=15","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15, #range for random rotations\n    rescale=1./255, #rescaling factor to transform every pixel value from range [0,255] -> [0,1]\n    shear_range=0.1, #shear intensity, the image will be distorted along an axis\n    zoom_range=0.2, #zoom in an image\n    horizontal_flip=True, #randomly flip inputs horizontally\n    width_shift_range=0.1, #shift horizontally(left or right)\n    height_shift_range=0.1 #shift vertically(up or down)\n)\n\n#Takes the dataframe and the path to a directory and generates batches.\n#The generated batches contain augmented/normalized data.\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',#the type of label arrays that are returned (in this case categorical)\n    batch_size=batch_size\n)\n# train_generator = train_datagen.flow_from_directory(\n#     \"../input/garbage-classification/garbage classification/Garbage classification\", \n#     target_size=(300, 300),\n#     batch_size=16,\n#     class_mode='categorical',\n#     subset='training',\n#     seed=0\n# )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_datagen = ImageDataGenerator(rescale=1./255) #rescaling factor to transform every pixel value from range [0,255] -> [0,1]\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_df = train_df.sample(n=1).reset_index(drop=True) #n is number of images returned\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1) #(rows,columns,index)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_model.h5\")\nmodel.save_weights(\"weight_model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(12, 12))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy', color='red')\nplt.plot(val_acc, label='Validation Accuracy', color='blue')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='red')\nplt.plot(val_loss, label='Validation Loss', color='blue')\nplt.legend(loc='upper right')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.title('Training and Validation Loss')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x, test_y = validation_generator.__getitem__(1) #I think gets index 1 from dataframe (need to make sure)\n\nlabels = (train_generator.class_indices) #the mapping from class names to class indices\nlabels = dict((v,k) for k,v in labels.items()) #creates a dictionary by iterating through the indices\n\npreds = model.predict(test_x)\n\nplt.figure(figsize=(16, 16))\nfor i in range(15):\n    plt.subplot(4, 4, i+1)\n    plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n    plt.imshow(test_x[i])","metadata":{},"execution_count":null,"outputs":[]}]}