{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sb\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nimport keras.utils \nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"../input/garbage-classification/garbage classification/Garbage classification/\"))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:47:56.699413Z","iopub.execute_input":"2022-12-11T06:47:56.699846Z","iopub.status.idle":"2022-12-11T06:48:02.872020Z","shell.execute_reply.started":"2022-12-11T06:47:56.699759Z","shell.execute_reply":"2022-12-11T06:48:02.870831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Introduction\n\nThe project \"Classification of Trash Based on Recyclability Status\" aimed to develop a system that could take images of individual pieces of trash and classify them into one of five categories: glass, leather, paper, plastic, and metal. The system used a combination of computer vision and machine learning techniques to achieve this goal.\n\nThe first step in the process was to extract useful features from the images of the trash using a technique called Scale-Invariant Feature Transform (SIFT). This allowed the system to identify key points in the images that could be used to distinguish between the different types of trash.\n\nNext, the system used a machine learning algorithm called K-means clustering to group the images into clusters based on their visual characteristics. This allowed the system to automatically identify common patterns in the images and group them accordingly.\n\nFinally, the system used a support vector machine (SVM) to classify the images into their respective categories. The SVM used the output from the K-means clustering step to train itself, and was able to achieve an accuracy of 88% on the test data.\n\nOverall, the project demonstrated the effectiveness of using computer vision and machine learning techniques to automatically classify trash based on its recyclability status. This could potentially be useful in a variety of settings, including waste management facilities and households, to help people sort their trash more efficiently and reduce the amount of waste that ends up in landfills.\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"trash = pd.read_csv(\"/kaggle/input/garbage-classification/zero-indexed-files.txt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:02.874132Z","iopub.execute_input":"2022-12-11T06:48:02.874777Z","iopub.status.idle":"2022-12-11T06:48:02.896835Z","shell.execute_reply.started":"2022-12-11T06:48:02.874740Z","shell.execute_reply":"2022-12-11T06:48:02.895839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncategory = []\n# index = []\nfilename = []\nwith open(\"../input/garbage-classification/zero-indexed-files.txt\", \"r\") as file:\n    for line in file:     \n#      5>4?sd:dsds\n        # Category of the image (label) e.g. glass\n        cat = ''.join([i for i in line.split('.')[0] if not i.isdigit()])\n        category.append(cat)\n        \n        \n       #Image name e.g. glass/glass123.jpg\n        filename.append(cat+\"/\"+line.split(' ')[0])\n        \n        \n        #numerical value for category e.g. 0 for glass\n#         index.append((line.split(' ')[1]).strip()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:02.898086Z","iopub.execute_input":"2022-12-11T06:48:02.898746Z","iopub.status.idle":"2022-12-11T06:48:02.913825Z","shell.execute_reply.started":"2022-12-11T06:48:02.898710Z","shell.execute_reply":"2022-12-11T06:48:02.912704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\n    'filename':filename,\n    'category': category,\n#     'index': index\n})","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:02.917246Z","iopub.execute_input":"2022-12-11T06:48:02.917594Z","iopub.status.idle":"2022-12-11T06:48:02.923753Z","shell.execute_reply.started":"2022-12-11T06:48:02.917559Z","shell.execute_reply":"2022-12-11T06:48:02.921741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.title('Count plot')\nsb.countplot(x = df['category'], data=df)\n#Index 0: glass, Index 1: paper, Index 2: cardboard, Index 3: plastic, Index 4: metal, Index 5: other\n#<AxesSubplot:title={'center':'Count plot'}, xlabel='category', ylabel='count'>\n\nsample = random.choice(filename)\nfolder = ''.join([i for i in sample.split('.')[0] if not i.isdigit()])\n    \nimage = load_img(\"../input/garbage-classification/garbage classification/Garbage classification/\"+sample)\nplt.title(folder.split('/')[0])\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:02.925567Z","iopub.execute_input":"2022-12-11T06:48:02.926696Z","iopub.status.idle":"2022-12-11T06:48:03.283748Z","shell.execute_reply.started":"2022-12-11T06:48:02.926599Z","shell.execute_reply":"2022-12-11T06:48:03.282797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nFAST_RUN = False\nIMAGE_WIDTH=300\nIMAGE_HEIGHT=300\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\n#padding='same' returns output whose value can be computed by applying the filter to all input elements. \n#Border elements are computed using zero padding. \n#The output may be same or smaller than the input depending on the stride option.\n\nmodel = Sequential([\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.25),\n\n    Flatten(),\n\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(6, activation='softmax') #6 because we have 6 categories\n])\n\n#Computes the crossentropy loss between the labels and predictions.\n#acc metric to be evaluated by the model during training and testing\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:03.284802Z","iopub.execute_input":"2022-12-11T06:48:03.285123Z","iopub.status.idle":"2022-12-11T06:48:07.241127Z","shell.execute_reply.started":"2022-12-11T06:48:03.285090Z","shell.execute_reply":"2022-12-11T06:48:07.240086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n#stop training when a monitored metric has stopped improving.\n#patience: number of epochs with no improvement after which training will be stopped.\nearlystop = EarlyStopping(patience=10)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.242785Z","iopub.execute_input":"2022-12-11T06:48:07.243453Z","iopub.status.idle":"2022-12-11T06:48:07.249103Z","shell.execute_reply.started":"2022-12-11T06:48:07.243414Z","shell.execute_reply":"2022-12-11T06:48:07.248034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', #quantity to be monitored (in this case total loss)\n                                            patience=2, #number of epochs with no improvement after which learning rate will be reduced\n                                            verbose=1, #0: quiet, 1: update messages\n                                            factor=0.5, #factor by which the learning rate will be reduced\n                                            min_lr=0.00001) #lower bound on the learning rate.","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.252111Z","iopub.execute_input":"2022-12-11T06:48:07.252480Z","iopub.status.idle":"2022-12-11T06:48:07.259237Z","shell.execute_reply.started":"2022-12-11T06:48:07.252436Z","shell.execute_reply":"2022-12-11T06:48:07.258295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [earlystop, learning_rate_reduction]","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.261185Z","iopub.execute_input":"2022-12-11T06:48:07.261595Z","iopub.status.idle":"2022-12-11T06:48:07.270934Z","shell.execute_reply.started":"2022-12-11T06:48:07.261561Z","shell.execute_reply":"2022-12-11T06:48:07.269889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['index'] = df['category'] #.replace({0: 'glass', 1: 'paper', 2: 'cardboard', 3: 'plastic', 4: 'metal', 5: 'trash'}) \n# df.drop('index', inplace=True, axis=1)\ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)#42 is the seed of randomness\n\n#Incase a column was part of an index\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\n\nsb.countplot(x = train_df['category'])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.275538Z","iopub.execute_input":"2022-12-11T06:48:07.275904Z","iopub.status.idle":"2022-12-11T06:48:07.487898Z","shell.execute_reply.started":"2022-12-11T06:48:07.275879Z","shell.execute_reply":"2022-12-11T06:48:07.486921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.countplot(x = validate_df['category'])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.489266Z","iopub.execute_input":"2022-12-11T06:48:07.489590Z","iopub.status.idle":"2022-12-11T06:48:07.708040Z","shell.execute_reply.started":"2022-12-11T06:48:07.489556Z","shell.execute_reply":"2022-12-11T06:48:07.707160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#.shape[0]: gives number of rows\n#batch_size: number of training examples\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=15","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.709583Z","iopub.execute_input":"2022-12-11T06:48:07.709974Z","iopub.status.idle":"2022-12-11T06:48:07.715766Z","shell.execute_reply.started":"2022-12-11T06:48:07.709936Z","shell.execute_reply":"2022-12-11T06:48:07.714244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15, #range for random rotations\n    rescale=1./255, #rescaling factor to transform every pixel value from range [0,255] -> [0,1]\n    shear_range=0.1, #shear intensity, the image will be distorted along an axis\n    zoom_range=0.2, #zoom in an image\n    horizontal_flip=True, #randomly flip inputs horizontally\n    width_shift_range=0.1, #shift horizontally(left or right)\n    height_shift_range=0.1 #shift vertically(up or down)\n)\n\n#Takes the dataframe and the path to a directory and generates batches.\n#The generated batches contain augmented/normalized data.\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',#the type of label arrays that are returned (in this case categorical)\n    batch_size=batch_size\n)\n# train_generator = train_datagen.flow_from_directory(\n#     \"../input/garbage-classification/garbage classification/Garbage classification\", \n#     target_size=(300, 300),\n#     batch_size=16,\n#     class_mode='categorical',\n#     subset='training',\n#     seed=0\n# )","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:07.717563Z","iopub.execute_input":"2022-12-11T06:48:07.718039Z","iopub.status.idle":"2022-12-11T06:48:13.509820Z","shell.execute_reply.started":"2022-12-11T06:48:07.718003Z","shell.execute_reply":"2022-12-11T06:48:13.508792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_datagen = ImageDataGenerator(rescale=1./255) #rescaling factor to transform every pixel value from range [0,255] -> [0,1]\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:13.511470Z","iopub.execute_input":"2022-12-11T06:48:13.511855Z","iopub.status.idle":"2022-12-11T06:48:14.787044Z","shell.execute_reply.started":"2022-12-11T06:48:13.511818Z","shell.execute_reply":"2022-12-11T06:48:14.785998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_df = train_df.sample(n=1).reset_index(drop=True) #n is number of images returned\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"../input/garbage-classification/garbage classification/Garbage classification\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:14.788498Z","iopub.execute_input":"2022-12-11T06:48:14.788832Z","iopub.status.idle":"2022-12-11T06:48:14.798251Z","shell.execute_reply.started":"2022-12-11T06:48:14.788803Z","shell.execute_reply":"2022-12-11T06:48:14.797044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1) #(rows,columns,index)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:14.799924Z","iopub.execute_input":"2022-12-11T06:48:14.801178Z","iopub.status.idle":"2022-12-11T06:48:16.882986Z","shell.execute_reply.started":"2022-12-11T06:48:14.801140Z","shell.execute_reply":"2022-12-11T06:48:16.882003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_model.h5\")\nmodel.save_weights(\"weight_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:16.884354Z","iopub.execute_input":"2022-12-11T06:48:16.890413Z","iopub.status.idle":"2022-12-11T06:48:16.968556Z","shell.execute_reply.started":"2022-12-11T06:48:16.890376Z","shell.execute_reply":"2022-12-11T06:48:16.967605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n     train_generator, \n     epochs=60,\n     validation_data=validation_generator,\n     validation_steps=total_validate//batch_size,#specifies total number of steps taken from the generator before it is stopped at every epoch,its value is calculated as the total number of validation data points in data divided by the validation batch size.\n     steps_per_epoch=total_train//batch_size,#specifies total number of steps taken from the generator as soon as one epoch is finished and next epoch has started, its value is the total number of samples in the data divided by the batch size.\n     callbacks=callbacks\n )","metadata":{"execution":{"iopub.status.busy":"2022-12-11T06:48:16.969852Z","iopub.execute_input":"2022-12-11T06:48:16.970203Z","iopub.status.idle":"2022-12-11T07:46:18.312522Z","shell.execute_reply.started":"2022-12-11T06:48:16.970168Z","shell.execute_reply":"2022-12-11T07:46:18.311578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(12, 12))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy', color='red')\nplt.plot(val_acc, label='Validation Accuracy', color='blue')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='red')\nplt.plot(val_loss, label='Validation Loss', color='blue')\nplt.legend(loc='upper right')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.title('Training and Validation Loss')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T07:46:18.314138Z","iopub.execute_input":"2022-12-11T07:46:18.314622Z","iopub.status.idle":"2022-12-11T07:46:51.355463Z","shell.execute_reply.started":"2022-12-11T07:46:18.314585Z","shell.execute_reply":"2022-12-11T07:46:51.354569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x, test_y = validation_generator.__getitem__(1) #I think gets index 1 from dataframe (need to make sure)\n\nlabels = (train_generator.class_indices) #the mapping from class names to class indices\nlabels = dict((v,k) for k,v in labels.items()) #creates a dictionary by iterating through the indices\n\npreds = model.predict(test_x)\n\nplt.figure(figsize=(16, 16))\nfor i in range(15):\n    plt.subplot(4, 4, i+1)\n    plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n    plt.imshow(test_x[i])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T07:46:51.356901Z","iopub.execute_input":"2022-12-11T07:46:51.357899Z","iopub.status.idle":"2022-12-11T07:46:53.820017Z","shell.execute_reply.started":"2022-12-11T07:46:51.357862Z","shell.execute_reply":"2022-12-11T07:46:53.818928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install streamlit\n!pip install pyngrok===4.1.1\nfrom pyngrok import ngrok\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T07:46:53.821319Z","iopub.execute_input":"2022-12-11T07:46:53.827858Z","iopub.status.idle":"2022-12-11T07:47:20.958029Z","shell.execute_reply.started":"2022-12-11T07:46:53.827828Z","shell.execute_reply":"2022-12-11T07:47:20.956952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile main.py\n\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport streamlit as st\nfrom tensorflow.keras.models import load_model\n#load the model\nmodel = load_model('/kaggle/working/model_model.h5')\n#the model is loaded\nst.write(\"\"\"\n         # Trash Classification\n         \"\"\"\n         )\nst.write(\"This is a simple image classification web app to predict trash in an image\")\n#upload the image\nfile = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])\n#do predict the image\ndef import_and_predict(image_data, model):\n    size = (150,150)\n    image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n    img = np.asarray(image)\n    img_reshape = img[np.newaxis,...]\n    prediction = model.predict(img_reshape)\n    return prediction\nif file is None:\n    st.text(\"You haven't uploaded an image file\")\nelse:\n    image = Image.open(file)\n    st.image(image, use_column_width=True)\n    predictions = import_and_predict(image, model)\n    class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n    string = \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    st.write(string.format(class_names[np.argmax(predictions)], 100 * np.max(predictions)))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T07:47:20.962837Z","iopub.execute_input":"2022-12-11T07:47:20.963143Z","iopub.status.idle":"2022-12-11T07:47:20.970442Z","shell.execute_reply.started":"2022-12-11T07:47:20.963114Z","shell.execute_reply":"2022-12-11T07:47:20.969472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!nohup streamlit run main.py &\nurl = ngrok.connect(port='8501')\nurl","metadata":{"execution":{"iopub.status.busy":"2022-12-11T07:47:20.972276Z","iopub.execute_input":"2022-12-11T07:47:20.973372Z","iopub.status.idle":"2022-12-11T07:47:21.282020Z","shell.execute_reply.started":"2022-12-11T07:47:20.972766Z","shell.execute_reply":"2022-12-11T07:47:21.280545Z"},"trusted":true},"execution_count":null,"outputs":[]}]}